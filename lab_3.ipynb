{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "# from pymorphy2 import MorphAnalyzer\n",
    "from bedarev_analyzer import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/clear_text.txt\", 'r', encoding='utf8') as fp:\n",
    "    text = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGrammer():\n",
    "    morph = MorphAnalyzer()\n",
    "    DELIMITERS = (',', '.', '!', '?', ':')\n",
    "    \n",
    "    def __init__(self, text, min_count = 2):\n",
    "        for delimiter in self.DELIMITERS:\n",
    "            text = text.replace(delimiter, '\\n')\n",
    "        normal_text = [l for l in (self.normalize(line) for line in text.split('\\n')) if l]\n",
    "        self.min_count = max(2, min_count)\n",
    "        self.dicts_all_n_gramms = []\n",
    "\n",
    "        for n in range(1, max([len(l) for l in normal_text]) + 1):\n",
    "            all_n_gramms = []\n",
    "            for normal_line in normal_text:\n",
    "                if len(normal_line) < n:\n",
    "                    continue\n",
    "                n_gramms = self.get_n_gramm(normal_line, n)\n",
    "                if n_gramms:\n",
    "                        all_n_gramms.extend(n_gramms)\n",
    "            dict_all_n_gramms = {name: count for name, count in Counter(all_n_gramms).items() if name and count >= self.min_count}\n",
    "            if not dict_all_n_gramms:\n",
    "                break\n",
    "            self.dicts_all_n_gramms.append(dict_all_n_gramms)\n",
    "\n",
    "    @classmethod\n",
    "    def normalize(cls, line: str) -> List[str]:\n",
    "        return [w for w in [cls.morph.parse(word)[0].normal_form for word in\n",
    "                (v.lower() for v in re.findall(r\"('?[а-яА-ЯёЁ][а-яА-ЯёЁ]*(?:-[а-яА-ЯёЁ]+)*'?)\", line))] if w and w != ' ']\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n_gramm(words: list, n: int = 2): \n",
    "        return [tuple(words[i-n+1:i+1]) for i in range(n - 1, len(words))]\n",
    "\n",
    "    def max_n(self):\n",
    "        return len(self.dicts_all_n_gramms) - 1\n",
    "\n",
    "    def gramms(self, n=None):\n",
    "        result = Counter()\n",
    "        if n is None:\n",
    "            for i in self.dicts_all_n_gramms[1:]:\n",
    "                result += Counter(i)\n",
    "        else:\n",
    "            result = Counter(self.dicts_all_n_gramms[n-1])\n",
    "        result = Counter({' '.join(key): value for key, value in result.items()})\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = NGrammer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в работа', 872),\n",
       " ('на основа', 499),\n",
       " ('в г', 492),\n",
       " ('а также', 425),\n",
       " ('мочь быть', 421),\n",
       " ('с помощь', 382),\n",
       " ('при этом', 373),\n",
       " ('а в', 359),\n",
       " ('в который', 334),\n",
       " ('связанный с', 332)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammer.gramms().most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в данный работа', 162),\n",
       " ('в настоящее время', 157),\n",
       " ('в связь с', 145),\n",
       " ('по сравнение с', 143),\n",
       " ('в то время', 123),\n",
       " ('в зависимость от', 106),\n",
       " ('в соответствие с', 104),\n",
       " ('в этом случай', 101),\n",
       " ('в настоящий работа', 91),\n",
       " ('с точка зрение', 84)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammer.gramms(3).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('сотрудник который ученик евграфа сергеевича кузнецова принимать активный участие в покорение космос открытие космический эра летию первое инструментальный оптический исследование земной атмосфера из космос с пилотировать космический корабль ифа ан ссср миэиа мап с участие институт келдыша летию первое научный эксперимент',\n",
       "  2),\n",
       " ('который ученик евграфа сергеевича кузнецова принимать активный участие в покорение космос открытие космический эра летию первое инструментальный оптический исследование земной атмосфера из космос с пилотировать космический корабль ифа ан ссср миэиа мап с участие институт келдыша летию первое научный эксперимент по',\n",
       "  2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grammer.max_n())\n",
    "grammer.gramms(grammer.max_n()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
