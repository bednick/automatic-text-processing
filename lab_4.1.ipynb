{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedarev_semantic.base import *\n",
    "from bedarev_semantic.compile import SemanticVocabulary\n",
    "\n",
    "\n",
    "information = [\n",
    "    #\n",
    "    Synonyms(\n",
    "        'ДолжностноеЛицо',\n",
    "        {'рабочий', 'сотрудник', 'государственный служащий'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'РФ',\n",
    "        {'рф', 'россия', 'российский федерация'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Семья',\n",
    "        {'семья', 'ячейка общество'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'ЦБ',\n",
    "        {'цб', 'центральный банк', 'отечественный цб'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'ВВП',\n",
    "        {'ввп', 'валовый продукт'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'ОбразованныйЧеловек',\n",
    "        {'учёный', 'эксперт', 'академик'}\n",
    "    ),\n",
    "    GeneralPrivate(\n",
    "        'Государство',\n",
    "        {\n",
    "            Synonyms('РФ'),\n",
    "            'cccp',\n",
    "            'китай',\n",
    "            'сша'\n",
    "        },\n",
    "        values={'государство', 'страна', 'федерация'}\n",
    "    ),\n",
    "    GeneralPrivate(\n",
    "        'ДенежныеСредства',\n",
    "        {\n",
    "            'рубль',\n",
    "            'доллар',\n",
    "        },\n",
    "        {'деньга', 'средства', 'криптовалюта', 'валюта'}\n",
    "    ),\n",
    "    #\n",
    "    GeneralPrivate(\n",
    "        'Числительные',\n",
    "        {\n",
    "            'нуль',\n",
    "            'три',\n",
    "            'два',\n",
    "            'миллион',\n",
    "            'миллиардмиллиард',\n",
    "        },\n",
    "        {'число', 'количество'}\n",
    "    ),\n",
    "    # транзакции -> приход и расход\n",
    "    GeneralPrivate(\n",
    "        'Субъект',\n",
    "        {\n",
    "            'округ',\n",
    "            'страна',\n",
    "        },\n",
    "        {'субъект', }\n",
    "    ),\n",
    "    PartWhole(\n",
    "        'ПланетнаяСистема',\n",
    "        {\n",
    "            GeneralPrivate('Звезда', {'солнце'}, {'звезда'}),\n",
    "            GeneralPrivate('Спутник', {'луна'}, {'спутник'}),\n",
    "            GeneralPrivate('Планета', {'земля'}, {'планета'})\n",
    "        },\n",
    "        {'планетный система', }\n",
    "    ),\n",
    "    GeneralPrivate(\n",
    "        'НаучнаяОбласть',\n",
    "        {\n",
    "            'математика',\n",
    "            'физика',\n",
    "            'информационные технологии',\n",
    "        },\n",
    "        {'наука'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'ПротопланетныйДиск',\n",
    "        {'протопланетный диск', 'протопланетный кольцо'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Затрата',\n",
    "        {'затрата', 'издержка'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Финансирование',\n",
    "        {'кредит', 'кредитование',\n",
    "         'вклад', 'финансирование', 'инвестиция'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Налогообложение',\n",
    "        {'налог', 'налоговый нагрузка'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Регулирование',\n",
    "        {'регулирование', 'управление'}\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Банк',\n",
    "        {'банк', 'банковский система'}\n",
    "    ),\n",
    "    PartWhole(\n",
    "        'Правительство',\n",
    "        {\n",
    "            'мгд',\n",
    "            'институт'\n",
    "        },\n",
    "        {'правительство', 'власть'}\n",
    "    ),\n",
    "    GeneralPrivate(\n",
    "        'ПолезноеИскопаемое',\n",
    "        {\n",
    "            'газ',\n",
    "            'нефть',\n",
    "        },\n",
    "        {'полезный ископаемое', 'ресурс'}\n",
    "    ),\n",
    "    PartWhole(\n",
    "        'ВременнойОтрезок',\n",
    "        {\n",
    "            'x годах',\n",
    "            Synonyms(\n",
    "                'НастоящееВремя',\n",
    "                {'последний время', 'сегодня', 'сейчас', 'настоящее время'}\n",
    "            ),\n",
    "        },\n",
    "    ),\n",
    "    Synonyms(\n",
    "        'Аглоритм',\n",
    "        {'алгоритм', 'технология', 'схема', 'подход'}\n",
    "    ),\n",
    "]\n",
    "\n",
    "voc = SemanticVocabulary(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, Tuple, Union\n",
    "\n",
    "def get_values(obj: Union[str, SemanticObject]) -> Set[str]:\n",
    "    if isinstance(obj, str):\n",
    "        return {obj}\n",
    "    all_values = set()\n",
    "    for value in obj.values():\n",
    "        all_values |= get_values(value)\n",
    "    return all_values\n",
    "\n",
    "\n",
    "def get_values_followers(obj: Union[SemanticObject]) -> Set[str]:\n",
    "    all_values = set()\n",
    "    for follower in obj.followers:\n",
    "        if isinstance(obj, str):\n",
    "            all_values.add(obj)\n",
    "        else:\n",
    "            all_values |= get_values(follower)\n",
    "    return all_values\n",
    "\n",
    "\n",
    "def top_down_algorithm(phrase: str, semantic_vocabulary: SemanticVocabulary,\n",
    "                       weight_synonyms: float = 0.9,\n",
    "                       weight_general_private: float = 0.5,\n",
    "                       weight_part_whole: float = 0.25) -> Set[Tuple[float, str]]:\n",
    "    result = set()\n",
    "    \n",
    "    for search in semantic_vocabulary.search(phrase):\n",
    "        if isinstance(search, Synonyms):\n",
    "            result |= {(weight_synonyms, v) for v in get_values(search) if v != phrase}\n",
    "        elif isinstance(search, GeneralPrivate):\n",
    "            result |= {(weight_synonyms, v) for v in get_values(search) if v != phrase}\n",
    "            result |= {(weight_general_private, v) for v in get_values_followers(search)}\n",
    "        elif isinstance(search, PartWhole):\n",
    "            result |= {(weight_synonyms, v) for v in get_values(search) if v != phrase}\n",
    "            result |= {(weight_part_whole, v) for v in get_values_followers(search)}\n",
    "    \n",
    "    return {(res[0], '_'.join(res[1].split(' '))) for res in result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(top_down_algorithm('рф', voc))\n",
    "# print(top_down_algorithm('государство', voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Set, Dict\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "DELIMITERS = (',', '.', '!', '?', ':', ';')\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def normalize_line(line: str,) -> List[List[Set[str]]]:\n",
    "    for delimiter in DELIMITERS:\n",
    "            line = line.replace(delimiter, '\\n')\n",
    "    phrases = line.split('\\n')\n",
    "    \n",
    "    normalize_sequence = []\n",
    "    after_start = 0\n",
    "    for phrase in phrases:\n",
    "        normalize_phrase = []\n",
    "        while phrase:\n",
    "            search = re.search(r\"('?[а-яА-ЯёЁ][а-яА-ЯёЁ]*(?:-[а-яА-ЯёЁ]+)*'?)\", phrase)\n",
    "            if not search:\n",
    "                after_start += len(phrase)\n",
    "                break\n",
    "            else:\n",
    "                start = search.start()\n",
    "                end = search.end()\n",
    "                phrase = phrase[end:]\n",
    "                word = search.group(0).lower()\n",
    "                forms = set([parse.normal_form for parse in morph.parse(word) if parse.normal_form != ' '])\n",
    "                if forms:\n",
    "                    normalize_phrase.append(((start+after_start, end+after_start), forms))\n",
    "                after_start += end\n",
    "        after_start += 1\n",
    "        if normalize_phrase:\n",
    "            normalize_sequence.append(normalize_phrase)\n",
    "\n",
    "    return normalize_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/clear_text.txt\", 'r', encoding='utf8') as fp:\n",
    "    text = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_lines = [normalize_line(line) for line in text_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_n_gramms = pd.read_csv('./data/all_n_gramms.csv')\n",
    "correct_n_gram = all_n_gramms[(all_n_gramms.idf > 0.5) & ((all_n_gramms.frequency > 2) & (all_n_gramms.N < 5))]\n",
    "\n",
    "MAX_N = correct_n_gram.N.max()\n",
    "MAX_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FORMS = set(form.replace(' ', '_') for form in correct_n_gram.form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'полезный_ископаемое' in ALL_FORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_n_grams_from_phrase(phrase: List[Tuple[Tuple[int,int], Set[str]]]):\n",
    "    result = []\n",
    "#     for borders, words in phrase:\n",
    "#         result.extend([(borders[0], (word, )) for word in words])\n",
    "    if len(phrase) == 1:\n",
    "        return [(phrase[0][0][0], value) for value in phrase[0][1]]\n",
    "    \n",
    "    for n in range(1, min(MAX_N, len(phrase)+1)):\n",
    "        for i in range(0, len(phrase)-n+1):\n",
    "            res = ['_'.join(value) for value in itertools.product(*[pair[1] for pair in phrase][i:i+n])]\n",
    "            res = [v for v in res if v in ALL_FORMS]\n",
    "            if res:\n",
    "                result.extend([(phrase[i][0][0], r) for r in res])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_n_grams_from_sequence(sequence: List[List[Set[str]]]):\n",
    "    result = []\n",
    "    for phrase in sequence:\n",
    "        result.extend(get_n_grams_from_phrase(phrase))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(normalize_lines[0][2])\n",
    "# print(get_n_grams_from_phrase(normalize_lines[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_lines_with_grams = [get_n_grams_from_sequence(line) for line in normalize_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'условие'),\n",
       " (8, 'термодинамический'),\n",
       " (26, 'согласованность'),\n",
       " (42, 'иметь'),\n",
       " (48, 'большой'),\n",
       " (56, 'значение'),\n",
       " (8, 'термодинамический_согласованность'),\n",
       " (42, 'иметь_большой'),\n",
       " (48, 'большой_значение'),\n",
       " (66, 'например'),\n",
       " (75, 'при'),\n",
       " (79, 'использование'),\n",
       " (93, 'уравнение'),\n",
       " (103, 'состояние'),\n",
       " (113, 'век'),\n",
       " (115, 'газодинамический'),\n",
       " (132, 'расчёт'),\n",
       " (75, 'при_использование'),\n",
       " (79, 'использование_уравнение'),\n",
       " (93, 'уравнение_состояние'),\n",
       " (103, 'состояние_в'),\n",
       " (115, 'газодинамический_расчёт'),\n",
       " (75, 'при_использование_уравнение'),\n",
       " (141, 'век'),\n",
       " (143, 'дать'),\n",
       " (143, 'данный'),\n",
       " (150, 'работа'),\n",
       " (157, 'рассматриваться'),\n",
       " (173, 'вычисление'),\n",
       " (184, 'давление'),\n",
       " (193, 'век'),\n",
       " (195, 'модель'),\n",
       " (202, 'ограниченный'),\n",
       " (202, 'ограничить'),\n",
       " (216, 'атом'),\n",
       " (224, 'показываться'),\n",
       " (141, 'в_дать'),\n",
       " (141, 'в_данный'),\n",
       " (143, 'дать_работа'),\n",
       " (150, 'работа_рассматриваться'),\n",
       " (184, 'давление_в'),\n",
       " (193, 'в_модель'),\n",
       " (195, 'модель_ограниченный'),\n",
       " (202, 'ограниченный_атом'),\n",
       " (216, 'атом_и'),\n",
       " (222, 'и_показываться'),\n",
       " (141, 'в_дать_работа'),\n",
       " (143, 'дать_работа_рассматриваться'),\n",
       " (193, 'в_модель_ограниченный'),\n",
       " (195, 'модель_ограниченный_атом'),\n",
       " (238, 'что'),\n",
       " (242, 'при'),\n",
       " (246, 'использование'),\n",
       " (260, 'для'),\n",
       " (283, 'формула'),\n",
       " (291, 'из'),\n",
       " (294, 'работа'),\n",
       " (305, 'равенство'),\n",
       " (319, 'выполняться'),\n",
       " (331, 'лишь'),\n",
       " (336, 'приближённо'),\n",
       " (238, 'что_при'),\n",
       " (242, 'при_использование'),\n",
       " (246, 'использование_для'),\n",
       " (283, 'формула_из'),\n",
       " (291, 'из_работа'),\n",
       " (283, 'формула_из_работа'),\n",
       " (351, 'выражение'),\n",
       " (361, 'для'),\n",
       " (365, 'потенциал'),\n",
       " (398, 'век'),\n",
       " (400, 'модель'),\n",
       " (407, 'ограниченный'),\n",
       " (407, 'ограничить'),\n",
       " (421, 'атомать'),\n",
       " (428, 'модель'),\n",
       " (435, 'ограниченный'),\n",
       " (435, 'ограничить'),\n",
       " (449, 'атом'),\n",
       " (351, 'выражение_для'),\n",
       " (365, 'потенциал_и'),\n",
       " (398, 'в_модель'),\n",
       " (400, 'модель_ограниченный'),\n",
       " (407, 'ограниченный_атомать'),\n",
       " (421, 'атомать_модель'),\n",
       " (428, 'модель_ограниченный'),\n",
       " (435, 'ограниченный_атом'),\n",
       " (398, 'в_модель_ограниченный'),\n",
       " (400, 'модель_ограниченный_атомать'),\n",
       " (407, 'ограниченный_атомать_модель'),\n",
       " (421, 'атомать_модель_ограниченный'),\n",
       " (428, 'модель_ограниченный_атом'),\n",
       " (456, 'как'),\n",
       " (462, 'век'),\n",
       " (464, 'ряд'),\n",
       " (469, 'другой'),\n",
       " (476, 'модель'),\n",
       " (484, 'самосогласованный'),\n",
       " (503, 'поль'),\n",
       " (503, 'поле'),\n",
       " (456, 'как_и'),\n",
       " (460, 'и_в'),\n",
       " (462, 'в_ряд'),\n",
       " (464, 'ряд_другой'),\n",
       " (456, 'как_и_в'),\n",
       " (460, 'и_в_ряд'),\n",
       " (462, 'в_ряд_другой'),\n",
       " (509, 'рассматриваться'),\n",
       " (525, 'иона'),\n",
       " (532, 'среднее'),\n",
       " (532, 'средний'),\n",
       " (541, 'число'),\n",
       " (549, 'заполнение'),\n",
       " (560, 'век'),\n",
       " (562, 'электронейтральный'),\n",
       " (581, 'сферический'),\n",
       " (593, 'атомный'),\n",
       " (601, 'ячейка'),\n",
       " (608, 'радиус'),\n",
       " (529, 'с_средний'),\n",
       " (562, 'электронейтральный_сферический'),\n",
       " (581, 'сферический_атомный'),\n",
       " (593, 'атомный_ячейка'),\n",
       " (601, 'ячейка_радиус'),\n",
       " (562, 'электронейтральный_сферический_атомный'),\n",
       " (581, 'сферический_атомный_ячейка'),\n",
       " (593, 'атомный_ячейка_радиус')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_lines_with_grams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = []\n",
    "for normalize_line_with_grams in normalize_lines_with_grams:\n",
    "    dict_positions = {}\n",
    "    for position, phrase in normalize_line_with_grams:\n",
    "        dict_positions.setdefault(phrase, []).append(position)\n",
    "    positions.append(dict_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'условие': [0],\n",
       " 'термодинамический': [8],\n",
       " 'согласованность': [26],\n",
       " 'иметь': [42],\n",
       " 'большой': [48],\n",
       " 'значение': [56],\n",
       " 'термодинамический_согласованность': [8],\n",
       " 'иметь_большой': [42],\n",
       " 'большой_значение': [48],\n",
       " 'например': [66],\n",
       " 'при': [75, 242],\n",
       " 'использование': [79, 246],\n",
       " 'уравнение': [93],\n",
       " 'состояние': [103],\n",
       " 'век': [113, 141, 193, 398, 462, 560],\n",
       " 'газодинамический': [115],\n",
       " 'расчёт': [132],\n",
       " 'при_использование': [75, 242],\n",
       " 'использование_уравнение': [79],\n",
       " 'уравнение_состояние': [93],\n",
       " 'состояние_в': [103],\n",
       " 'газодинамический_расчёт': [115],\n",
       " 'при_использование_уравнение': [75],\n",
       " 'дать': [143],\n",
       " 'данный': [143],\n",
       " 'работа': [150, 294],\n",
       " 'рассматриваться': [157, 509],\n",
       " 'вычисление': [173],\n",
       " 'давление': [184],\n",
       " 'модель': [195, 400, 428, 476],\n",
       " 'ограниченный': [202, 407, 435],\n",
       " 'ограничить': [202, 407, 435],\n",
       " 'атом': [216, 449],\n",
       " 'показываться': [224],\n",
       " 'в_дать': [141],\n",
       " 'в_данный': [141],\n",
       " 'дать_работа': [143],\n",
       " 'работа_рассматриваться': [150],\n",
       " 'давление_в': [184],\n",
       " 'в_модель': [193, 398],\n",
       " 'модель_ограниченный': [195, 400, 428],\n",
       " 'ограниченный_атом': [202, 435],\n",
       " 'атом_и': [216],\n",
       " 'и_показываться': [222],\n",
       " 'в_дать_работа': [141],\n",
       " 'дать_работа_рассматриваться': [143],\n",
       " 'в_модель_ограниченный': [193, 398],\n",
       " 'модель_ограниченный_атом': [195, 428],\n",
       " 'что': [238],\n",
       " 'для': [260, 361],\n",
       " 'формула': [283],\n",
       " 'из': [291],\n",
       " 'равенство': [305],\n",
       " 'выполняться': [319],\n",
       " 'лишь': [331],\n",
       " 'приближённо': [336],\n",
       " 'что_при': [238],\n",
       " 'использование_для': [246],\n",
       " 'формула_из': [283],\n",
       " 'из_работа': [291],\n",
       " 'формула_из_работа': [283],\n",
       " 'выражение': [351],\n",
       " 'потенциал': [365],\n",
       " 'атомать': [421],\n",
       " 'выражение_для': [351],\n",
       " 'потенциал_и': [365],\n",
       " 'ограниченный_атомать': [407],\n",
       " 'атомать_модель': [421],\n",
       " 'модель_ограниченный_атомать': [400],\n",
       " 'ограниченный_атомать_модель': [407],\n",
       " 'атомать_модель_ограниченный': [421],\n",
       " 'как': [456],\n",
       " 'ряд': [464],\n",
       " 'другой': [469],\n",
       " 'самосогласованный': [484],\n",
       " 'поль': [503],\n",
       " 'поле': [503],\n",
       " 'как_и': [456],\n",
       " 'и_в': [460],\n",
       " 'в_ряд': [462],\n",
       " 'ряд_другой': [464],\n",
       " 'как_и_в': [456],\n",
       " 'и_в_ряд': [460],\n",
       " 'в_ряд_другой': [462],\n",
       " 'иона': [525],\n",
       " 'среднее': [532],\n",
       " 'средний': [532],\n",
       " 'число': [541],\n",
       " 'заполнение': [549],\n",
       " 'электронейтральный': [562],\n",
       " 'сферический': [581],\n",
       " 'атомный': [593],\n",
       " 'ячейка': [601],\n",
       " 'радиус': [608],\n",
       " 'с_средний': [529],\n",
       " 'электронейтральный_сферический': [562],\n",
       " 'сферический_атомный': [581],\n",
       " 'атомный_ячейка': [593],\n",
       " 'ячейка_радиус': [601],\n",
       " 'электронейтральный_сферический_атомный': [562],\n",
       " 'сферический_атомный_ячейка': [581],\n",
       " 'атомный_ячейка_радиус': [593]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize_lines_with_grams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "text_vectors = vectorizer.fit(ALL_FORMS)\n",
    "\n",
    "text_vectors = vectorizer.transform([' '.join([l[1] for l in line]) for line in normalize_lines_with_grams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request_words ['полезный', 'ископаемое', 'полезный_ископаемое']\n",
      "weights {(0.9, 'ресурс'), (0.5, 'нефть'), (1, 'полезный'), (1, 'полезный_ископаемое'), (0.5, 'газ'), (1, 'ископаемое')}\n",
      "vector_reques\n",
      "   (0, 7418)\t0.5\n",
      "  (0, 15757)\t1.0\n",
      "  (0, 25078)\t0.5\n",
      "  (0, 31782)\t1.0\n",
      "  (0, 31785)\t1.0\n",
      "  (0, 38269)\t0.9\n"
     ]
    }
   ],
   "source": [
    "reques = 'полезное ископаемое'\n",
    "\n",
    "request_words = [pair[1] for pair in get_n_grams_from_sequence(normalize_line(reques))]\n",
    "print('request_words', request_words)\n",
    "\n",
    "weights = {(1, phrase) for phrase in request_words}\n",
    "\n",
    "for phrase in request_words:\n",
    "    weights |= top_down_algorithm(phrase, voc)\n",
    "\n",
    "print('weights', weights)\n",
    "\n",
    "vector_reques = sum([weight * vectorizer.transform([phrase]) for weight, phrase in weights])\n",
    "\n",
    "print('vector_reques\\n', vector_reques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(request_words)\n",
    "# vector_reques = vectorizer.transform([' '.join(request_words)])\n",
    "# print()\n",
    "# print(vector_reques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(vector_reques.toarray()))\n",
    "# print(len(vector_reques.toarray()[0]))\n",
    "# print(vector_reques.shape)\n",
    "# vector_reques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(text_vectors.toarray()))\n",
    "# print(len(text_vectors.toarray()[0]))\n",
    "# print(text_vectors.shape)\n",
    "# text_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = text_vectors*vector_reques.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,(is_search, line) in enumerate(zip([res[0] for res in result.toarray()], text_lines)):\n",
    "#     if is_search:\n",
    "#         print(i)\n",
    "#         print(is_search)\n",
    "#         print(line)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_idex = [(i, is_search) for i, (is_search, line) in enumerate(zip([res[0] for res in result.toarray()], text_lines)) if is_search]\n",
    "results_idex.sort(key=lambda x: x[1], reverse=True)\n",
    "len(results_idex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3228, 9.0)\n",
      "{'полезный': [84, 219, 520], 'полезный_ископаемое': [84, 219, 520], 'ископаемое': [93, 228, 529]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Михеева в своем докладе выделяет 21 сырьевой регион РФ, ориентируясь на долю добычи полезных ископаемых в структуре ВРП. Используются также методы, основанные на соотношении объемов валовой добавленной стоимости добычи полезных ископаемых и обрабатывающих производств в субъектах РФ [21]. Для анализа стратегических документов социально-экономического развития сырьевых субъектов РФ в качестве ключевого критерия выделения сырьевых регионов России мы использовали показатель доли валовой добавленной стоимости от добычи полезных ископаемых в структуре ВРП (более 30% в период 2000–2010 гг.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "print(results_idex[i])\n",
    "line_positions = positions[results_idex[i][0]]\n",
    "res = {phrase: line_positions[phrase] for _, phrase in weights if phrase in line_positions}\n",
    "print(res)\n",
    "result_line = text_lines[results_idex[i][0]]\n",
    "result_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print_values = vector_reques.toarray()[0]\n",
    "\n",
    "# for i, v in enumerate(print_values):\n",
    "#     if v != 0:\n",
    "#         print(i, v, vectorizer.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
